{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+dnadFv7KCLkTnoH5yL3l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leojklarner/gauche/blob/main/notebooks/graph_kernel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installation \n",
        "\n",
        "!git clone https://github.com/leojklarner/gauche.git\n",
        "%cd gauche\n",
        "!pip install rdkit\n",
        "\n",
        "# !conda install pytorch torchvision torchaudio\n",
        "# !pip install scikit-learn pandas pytest tqdm jupyter\n",
        "\n",
        "!pip install gpytorch botorch selfies\n",
        "!pip install graphein==1.4.0\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kWfPRGSI4bUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq__ZII1K3Hx",
        "outputId": "5ceef5f2-97d1-4dbf-d685-ad1e111237a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial  1 of 20 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gpytorch/lazy/lazy_tensor.py:1811: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
            "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
            "X = torch.triangular_solve(B, A).solution\n",
            "should be replaced with\n",
            "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2183.)\n",
            "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "....................\n",
            "Trial  2 of 20 ....................\n",
            "Trial  3 of 20 ....................\n",
            "Trial  4 of 20 ....................\n",
            "Trial  5 of 20 ....................\n",
            "Trial  6 of 20 ....................\n",
            "Trial  7 of 20 ....................\n",
            "Trial  8 of 20 ....................\n",
            "Trial  9 of 20 ....................\n",
            "Trial 10 of 20 ....................\n",
            "Trial 11 of 20 ....................\n",
            "Trial 12 of 20 ....................\n",
            "Trial 13 of 20 ....................\n",
            "Trial 14 of 20 ....................\n",
            "Trial 15 of 20 ....................\n",
            "Trial 16 of 20 ....................\n",
            "Trial 17 of 20 ....................\n",
            "Trial 18 of 20 ....................\n",
            "Trial 19 of 20 .........."
          ]
        }
      ],
      "source": [
        "import sys, time, warnings, numpy as np, torch, random\n",
        "sys.path.append('..')\n",
        "from matplotlib import pyplot as plt\n",
        "from rdkit.Chem import MolFromSmiles\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from botorch import fit_gpytorch_model\n",
        "from botorch.acquisition import ExpectedImprovement\n",
        "from botorch.exceptions import BadInitialCandidatesWarning\n",
        "from botorch.models.gp_regression import SingleTaskGP\n",
        "\n",
        "from gpytorch.distributions import MultivariateNormal\n",
        "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
        "from gpytorch.likelihoods import GaussianLikelihood\n",
        "from gpytorch.means import ConstantMean\n",
        "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
        "\n",
        "from gprotorch.dataloader import DataLoaderMP\n",
        "from gprotorch.kernels.gnn_kernels.pretrained_kernel import GNN, mol_to_pyg\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic=True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# We define our custom GP surrogate model using the RBF kernel\n",
        "class GP_PretrainedKernel(SingleTaskGP):\n",
        "\n",
        "    def __init__(self, train_X, train_Y):\n",
        "        super().__init__(train_X, train_Y, GaussianLikelihood())\n",
        "        self.mean_module = ConstantMean()\n",
        "        self.covar_module = ScaleKernel(base_kernel=RBFKernel())\n",
        "        self.to(train_X)  # make sure we're on the right device/dtype\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean_x = self.mean_module(x)\n",
        "        covar_x = self.covar_module(x)\n",
        "        return MultivariateNormal(mean_x, covar_x)\n",
        "\n",
        "\"\"\"We define helper functions for the Bayesian optimisation loop.\n",
        " In particular the acquisition function optimisation procedure\n",
        " is framed so as to take the maximum over a discrete \n",
        " set of heldout molecules.\"\"\"\n",
        "\n",
        "def initialize_model(train_x, train_obj, state_dict=None):\n",
        "    \"\"\"\n",
        "    Initialise model and loss function.\n",
        "    Args:\n",
        "        train_x: tensor of inputs\n",
        "        train_obj: tensor of outputs\n",
        "        state_dict: current state dict used to speed up fitting\n",
        "    Returns: mll object, model object\n",
        "    \"\"\"\n",
        "\n",
        "    # define model for objective\n",
        "    model = GP_PretrainedKernel(train_x, train_obj).to(train_x)\n",
        "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
        "    # load state dict if it is passed\n",
        "    if state_dict is not None:\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "    return mll, model\n",
        "\n",
        "\n",
        "def optimize_acqf_and_get_observation(\n",
        "    acq_func, heldout_inputs, heldout_outputs):\n",
        "    \"\"\"\n",
        "    Optimizes the acquisition function, and returns a \n",
        "    new candidate and an observation.\n",
        "    Args:\n",
        "        acq_func: Object representing the acquisition function\n",
        "        heldout_points: Tensor of heldout points\n",
        "    Returns: new_x, new_obj\n",
        "    \"\"\"\n",
        "\n",
        "    # Loop over the discrete set of points to evaluate \n",
        "    # the acquisition function at.\n",
        "    acq_vals = []\n",
        "    for i in range(len(heldout_outputs)):\n",
        "        acq_vals.append(acq_func(heldout_inputs[i].unsqueeze(-2)))  \n",
        "        # use unsqueeze to append batch dimension\n",
        "\n",
        "    # observe new values\n",
        "    acq_vals = torch.tensor(acq_vals)\n",
        "    best_idx = torch.argmax(acq_vals)\n",
        "    new_x = heldout_inputs[best_idx].unsqueeze(-2)  \n",
        "    # add batch dimension\n",
        "    new_obj = heldout_outputs[best_idx].unsqueeze(-1)  \n",
        "    # add output dimension\n",
        "\n",
        "    # Delete the selected input and value from the heldout set.\n",
        "    heldout_inputs = torch.cat(\n",
        "        (heldout_inputs[:best_idx], heldout_inputs[best_idx+1:]), axis=0)\n",
        "    heldout_outputs = torch.cat(\n",
        "        (heldout_outputs[:best_idx], heldout_outputs[best_idx+1:]), axis=0)\n",
        "\n",
        "    return new_x, new_obj, heldout_inputs, heldout_outputs\n",
        "\n",
        "\n",
        "def update_random_observations(\n",
        "    best_random, heldout_inputs, heldout_outputs):\n",
        "    \"\"\"\n",
        "    Simulates a random policy by taking a the current list of \n",
        "    best values observed randomly,\n",
        "    drawing a new random point from the heldout set, observing its value,\n",
        "    and updating the list.\n",
        "    Args:\n",
        "        best_random: List of best random values observed so far\n",
        "        heldout_inputs: Tensor of inputs\n",
        "        heldout_outputs: Tensor of output values\n",
        "    Returns: best_random, float specifying the objective function value.\n",
        "    \"\"\"\n",
        "\n",
        "    # Take a random sample by permuting the indices and selecting \n",
        "    # the first element.\n",
        "    index = torch.randperm(len(heldout_outputs))[0]\n",
        "    next_random_best = heldout_outputs[index]\n",
        "    best_random.append(max(best_random[-1], next_random_best))\n",
        "\n",
        "    # Delete the selected input and value from the heldout set.\n",
        "    heldout_inputs = torch.cat(\n",
        "        (heldout_inputs[:index], heldout_inputs[index+1:]), axis=0)\n",
        "    heldout_outputs = torch.cat(\n",
        "        (heldout_outputs[:index], heldout_outputs[index+1:]), axis=0)\n",
        "\n",
        "    return best_random, heldout_inputs, heldout_outputs\n",
        "\n",
        "\"\"\"Run the Bayesian optimisation loop, comparing the analytic \n",
        "(sequential) expected improvement acquisition funciton with \n",
        "a random policy.\"\"\"\n",
        "\n",
        "# Bayesian optimisation experiment parameters, number \n",
        "# of random trials, split size, batch size\n",
        "# and number of iterations of Bayesian optimisation.\n",
        "\n",
        "N_TRIALS = 20\n",
        "holdout_set_size = 0.95\n",
        "N_ITERS = 20\n",
        "verbose = False\n",
        "set_seed(12)\n",
        "\n",
        "warnings.filterwarnings('ignore', category=BadInitialCandidatesWarning)\n",
        "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
        "\n",
        "best_observed_all_ei, best_random_all = [], []\n",
        "\n",
        "# Load the Photoswitch dataset\n",
        "loader = DataLoaderMP()\n",
        "loader.load_benchmark(\n",
        "    \"Photoswitch\", \"data/property_prediction/photoswitches.csv\")\n",
        "\n",
        "# We use the fragprints representations (a concatenation \n",
        "# of Morgan fingerprints and RDKit fragment features)\n",
        "y = loader.labels\n",
        "\n",
        "# get PyTorch Geometric featurisation of molecules\n",
        "graphs = [\n",
        "    mol_to_pyg(MolFromSmiles(smiles)) for smiles in loader.features\n",
        "]\n",
        "\n",
        "# load pretrained model\n",
        "with torch.no_grad():\n",
        "    model = GNN(gnn_type='gin')\n",
        "    model.load_pretrained('contextpred', device=torch.device(\"cpu\"))\n",
        "\n",
        "    X = torch.stack(\n",
        "        [\n",
        "            model(\n",
        "                x=graphs[i].x,\n",
        "                edge_index=graphs[i].edge_index,\n",
        "                edge_attr=graphs[i].edge_attr,\n",
        "            ).mean(0) for i in range(len(graphs))\n",
        "        ]\n",
        "    )\n",
        "\n",
        "# average over multiple random trials (each trial splits\n",
        "# the initial training set for the GP in a random manner)\n",
        "for trial in range(1, N_TRIALS + 1):\n",
        "\n",
        "    print(f\"\\nTrial {trial:>2} of {N_TRIALS} \", end=\"\")\n",
        "    best_observed_ei, best_random = [], []\n",
        "\n",
        "    # Generate initial training data and initialize model\n",
        "    train_x_ei, heldout_x_ei, train_y_ei, heldout_y_ei = train_test_split(\n",
        "        X, y, test_size=holdout_set_size, random_state=trial)\n",
        "    best_observed_value_ei = torch.tensor(np.max(train_y_ei))\n",
        "\n",
        "    # Convert numpy arrays to PyTorch tensors and flatten the label vectors\n",
        "    train_y_ei = torch.tensor(train_y_ei)\n",
        "    heldout_y_ei = torch.tensor(heldout_y_ei)\n",
        "\n",
        "    # The initial heldout set is the same for random search\n",
        "    heldout_x_random = heldout_x_ei\n",
        "    heldout_y_random = heldout_y_ei\n",
        "\n",
        "    mll_ei, model_ei = initialize_model(train_x_ei, train_y_ei)\n",
        "\n",
        "    best_observed_ei.append(best_observed_value_ei)\n",
        "    best_random.append(best_observed_value_ei)\n",
        "\n",
        "    # run N_ITERS rounds of BayesOpt after the initial random batch\n",
        "    for iteration in range(1, N_ITERS + 1):\n",
        "\n",
        "        t0 = time.time()\n",
        "\n",
        "        # fit the model\n",
        "        fit_gpytorch_model(mll_ei)\n",
        "\n",
        "        # Use analytic acquisition function for batch size of 1.\n",
        "        EI = ExpectedImprovement(model=model_ei, best_f=\\\n",
        "        (train_y_ei.to(train_y_ei)).max())\n",
        "\n",
        "        new_x_ei, new_obj_ei, heldout_x_ei, heldout_y_ei =\\\n",
        "        optimize_acqf_and_get_observation(EI, heldout_x_ei, heldout_y_ei)\n",
        "\n",
        "        # update training points\n",
        "        train_x_ei = torch.cat([train_x_ei, new_x_ei])\n",
        "        train_y_ei = torch.cat([train_y_ei, new_obj_ei])\n",
        "\n",
        "        # update random search progress\n",
        "        best_random, heldout_x_random, heldout_y_random =\\ \n",
        "        update_random_observations(best_random, \n",
        "                                   heldout_inputs=heldout_x_random,\n",
        "                                   heldout_outputs=heldout_y_random)\n",
        "        best_value_ei = torch.max(new_obj_ei, best_observed_ei[-1])\n",
        "        best_observed_ei.append(best_value_ei)\n",
        "\n",
        "        # reinitialise the model so it is ready for fitting on the next\n",
        "        # iteration use the current state dict to speed up fitting\n",
        "        mll_ei, model_ei = initialize_model(\n",
        "            train_x_ei,\n",
        "            train_y_ei,\n",
        "            model_ei.state_dict(),\n",
        "        )\n",
        "\n",
        "        t1 = time.time()\n",
        "\n",
        "        if verbose:\n",
        "            print(\n",
        "                f\"\\nBatch {iteration:>2}: best_value (random, qEI) = \"\n",
        "                f\"({max(best_random):>4.2f}, {best_value_ei:>4.2f}), \"\n",
        "                f\"time = {t1 - t0:>4.2f}.\", end=\"\"\n",
        "            )\n",
        "        else:\n",
        "            print(\".\", end=\"\")\n",
        "\n",
        "    best_observed_all_ei.append(best_observed_ei)\n",
        "    best_random_all.append(best_random)\n",
        "\n",
        "# Define a confience interval function for plotting.\n",
        "def ci(y):\n",
        "    return 1.96 * y.std(axis=0) / np.sqrt(N_TRIALS)\n",
        "\n",
        "iters = np.arange(N_ITERS + 1)\n",
        "\n",
        "y_ei = []\n",
        "for i in range(len(best_observed_all_ei)):\n",
        "    y_ei_inner = []\n",
        "    for j in range(len(best_observed_all_ei[i])):\n",
        "        y_ei_inner.append(best_observed_all_ei[i][j].item())\n",
        "    y_ei.append(y_ei_inner)\n",
        "y_ei = np.asarray(y_ei)\n",
        "\n",
        "y_rnd = []\n",
        "for i in range(len(best_random_all)):\n",
        "    y_rnd_inner = []\n",
        "    for j in range(len(best_random_all[i])):\n",
        "        y_rnd_inner.append(best_random_all[i][j].item())\n",
        "    y_rnd.append(y_rnd_inner)\n",
        "y_rnd = np.asarray(y_rnd)\n",
        "\n",
        "y_rnd_mean = y_rnd.mean(axis=0)\n",
        "y_ei_mean = y_ei.mean(axis=0)\n",
        "y_rnd_std = y_rnd.std(axis=0)\n",
        "y_ei_std = y_ei.std(axis=0)\n",
        "\n",
        "lower_rnd = y_rnd_mean - y_rnd_std\n",
        "upper_rnd = y_rnd_mean + y_rnd_std\n",
        "lower_ei = y_ei_mean - y_ei_std\n",
        "upper_ei = y_ei_mean + y_ei_std\n",
        "\n",
        "plt.plot(iters, y_rnd_mean, label='Random')\n",
        "plt.fill_between(iters, lower_rnd, upper_rnd, alpha=0.2)\n",
        "plt.plot(iters, y_ei_mean, label='EI')\n",
        "plt.fill_between(iters, lower_ei, upper_ei, alpha=0.2)\n",
        "plt.xlabel('Number of Iterations')\n",
        "plt.ylabel('Best Objective Value')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.xticks(list(np.arange(1, 21)))\n",
        "plt.show()\n",
        "\n",
        "\"\"\"\n",
        "EI outperforms random search in terms of selecting molecules with \n",
        "high E isomer pi-pi* transition wavelength! It should be noted that\n",
        "the true objective for photoswitch optimisation would consider all \n",
        "transition wavelengths as well as the thermal half-life and this \n",
        "will hopefully be included in a future notebook!\n",
        "\"\"\""
      ]
    }
  ]
}